---
title:          "L4: Diagnosing Large-scale LLM Training Failures via Automated Log Analysis"
date:           2025-03-25 00:00:00 +0800
selected:       true
pub:            >-
                The ACM International Conference on the Foundations of Software Engineering, Industry, Trondheim, Norway, Jun 2025.
pub_pre:        >-
                <span class="badge badge-pill badge-custom badge-success">FSE'25</span>
# pub_post:       'Under review.'
abstract: >-
    The training process of Large Language Models (LLMs) requires substantial resources, as evidenced by scaling laws, which frequently leads to inevitable failures.
    In this paper, we present the first empirical study of LLM training failures on our production platform.
    Leveraging the obtained insights and the distinct cross-job, spatial, and temporal patterns present in LLM training logs, we propose L4, the first log-based large-scale LLM training failure diagnosis framework, which can automatically extract failure-indicating information (i.e., log events, nodes, stages, and iterations) from extensive training logs, thereby reducing manual effort and facilitating failure recovery.
authors:
    - Zhihan Jiang
    - Junjie Huang
    - Guangba Yuâ€ 
    - Zhuangbin Chen
    - Yichen Li
    - Renyi Zhong
    - Cong Feng
    - Yongqiang Yang
    - Zengyin Yang
    - Michael R. Lyu
links:
  Paper: https://www.zhihan-jiang.com/files/FSE25/L4.pdf
  Arxiv: https://arxiv.org/abs/2503.20263
  Slides:
  DOI:
  BibTex:
---
